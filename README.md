# One Billion Row Challenge with Python

В начале 2024 года прошла волна челенджа "Один Миллиард Строк".  Он первоначально предназначался для программистов Java и состоит в следующем:
- необходимо сгенерировать файл с одним ярдом строк в формате CSV;
- необходимо его прочитать и подсчитать статистики;
- желательно все это сделать быстро.

Мне стало интересно в учебных целях сделать все то же самое в интерактивном Python.  Постепенно я расширил задачу и решил еще поэкспериментировать с файлом в формате parquet. Проблема в том, что файл такого размера с трудом влез в 16G оперативы и при попытке сделать аналитическую свертку грохал ядро.  Основные сложности: 
- генерация файла такого размера в форматах CSV и parquet,
- инкрементальная обработка данных такого размера в Pandas и Polars,
- знакомство с DuckDB.

Основные выводы: 
- DuckDB на основе parquet работает быстрее всего.  
- Надо активнее использовать parquet на основе pyarrow для создания собственных мелких озер данных. 
- Надо активнее использовать SQL и DuckDB даже для простого чтения CSV.

Файлы в репозитории: 
-    - исходник с названиями метерологических станций,
-  - Блокнот со всеми экспериментами.
 
Благодарности: 
- https://github.com/lvgalvao/  за снипеты кода
- https://github.com/gunnarmorling/ за сам челендж
